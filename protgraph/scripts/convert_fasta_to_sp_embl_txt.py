import argparse
import csv
import os
from datetime import date

import tqdm

from protgraph.cli import check_if_file_exists

SWISS_EMBL_SKELETON = \
    """{ID_AC}
DT   {DAY}-{MONTH}-{YEAR}, integrated into UTA.
DT   {DAY}-{MONTH}-{YEAR}, sequence version 1.
DT   {DAY}-{MONTH}-{YEAR}, entry version 1.
DE   RecName: Full={PROTEIN_DESC};
GN   Name={GENE}; Synonyms={GENE}; ORFNames={GENE};
OS   Autogenerated.
OC   Autogenerated.
OX   NCBI_TaxID=0000;
RN   [1]
RP   AUTOGENERATED
RA   This file was autogenerated;
RT   "This is an autogenerated file.";
RL   (er) Autogenerated.
CC   -!- CAUTION: This file was autogenerated and sequences
CC       can differ from UniProt!
DR   UTA; {ENSP}; Universal Transcript Archive
PE   4: Predicted;
KW   Generated for ProtGraph{FT}
{SQ}
{SEQ_BODY}//
"""


def parse_args():
    """ Parse Arguments """
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
        description="Small script to create a SP-EMBL-txt-Entries from FASTA-entries."
        "This can be very useful for FASTA-database and -entries, which are NOT in UniProt but should be utilized by "
        "ProtGraph. Currently only a plain conversion from FASTA to SP-EMBL is provided. However this could be "
        "extended to include further feature information to peptides (like variants) using a csv entry. Note: The "
        "header should have 3 section '<pre>|<accession>|<description>', where the accession is unique for the whole "
        "FASTA-file."
    )

    # Number of entries in fasta (for tqdm)
    parser.add_argument(
        "--num_entries", "-n", type=int, default=None,
        help="Number of entries in the fasta files. if provided, it can give an estimate of the running time."
    )

    # Base Folder of generated Pickle Files
    parser.add_argument(
        "fasta_file", type=check_if_file_exists, nargs=1,
        help="Fasta file, where the header should be replaced"
    )

    # Feature-Table-Mapping
    parser.add_argument(
        "--feature_tables", "-ft", type=str, default=None,
        help="TSV file with feature annotations.\n"
             "Required columns: accession, type, type_specific, description\n"
             "Supported feature types with their type_specific syntax:\n"
             "  • VARIANT/CONFLICT/MUTAGEN:\n"
             "    - Replacement: 'A,V,123' (original,new,position)\n"
             "    - Deletion:    'Missing,123' (position)\n"
             "  • SIGNAL/CHAIN/PROPEP/PEPTIDE:\n"
             "    - Position range: '1..20' or single position '123'\n"
             "  • INIT_MET:\n"
             "    - Has no type_specific syntax (can be empty)\n\n"
             "NOTE: Position can in all cases either be X..Y or a single position X.\n\n"
             "Examples:\n"
             "  P12345\\tVARIANT\\tADV,V,123-125\\tReplacing ADV with V at position 123-125\n"
             "  P12345\\tMUTAGEN\\tMissing,63\\tDeletion of Aminoacid at position 63\n"
             "  P12345\\tCHAIN\\t1..300\\tProtein chain from residue 1 to 300\n"
             "  P12345\\tSIGNAL\\t1..20\\tSignal peptide sequence"
    )

    # Output SP-EMBL-file
    parser.add_argument(
        "--output", "-o", type=str, default="output.txt",
        help="Output fasta file. DEFAULT 'output.fasta' (NOTE: This file WILL be overwritten)"
    )

    return parser.parse_args()


def get_next_fasta_entry(fasta) -> tuple:
    """ Generator, returning parsed FASTA-entries """
    get_sequence = False  # Flag to stop after the sequence was retrieved
    sequence = ""
    pre = ""
    accession = ""
    description = ""

    for line in fasta:
        # Iterate over each line of the FASTA-database
        if line.startswith(">"):
            # Case it is the header file
            if get_sequence:
                # We reached the next entry and can report the protein
                if sequence.isalpha() and sequence.isupper():
                    yield sequence, pre, accession, description
                    sequence = ""
                    get_sequence = False
                else:
                    print("WARNING: Entry {acc} has a malformed sequence".format(acc=accession))

            # Parse header information. Maybe we could extend this to regex?
            pre, accession, description = line[1:-1].split("|", 2)
            get_sequence = True

        else:
            # Simply append the sequences if we want to get it .
            if get_sequence:
                sequence += line[:-1]
    if sequence.isalpha() and sequence.isupper():
        yield sequence, pre, accession, description
    else:
        print("WARNING: Entry {acc} has a malformed sequence".format(acc=accession))


def _get_seq_string(sequence) -> str:
    """ Converts a string to SP-EMBL-txt """
    final_str = ""
    for seq in [sequence[i:i+60] for i in range(0, len(sequence), 60)]:
        final_str += "     " + " ".join(seq[i:i+10] for i in range(0, len(seq), 10)) + "\n"

    return final_str


def _get_seq_header_string(sequence_len: int) -> str:
    """ Generates the sequence header for the sequence """
    return "SQ   SEQUENCE   {} AA;  {} MW;  {} CRC64;".format(
        sequence_len,
        12345,  # Does not need to be set for ProtGraph
        "45D66B0D27B69FCD"  # Does not need to be set for ProtGraph
    )


def _get_id_ac_string(accession: str, gene: str, sequence_len: int) -> str:
    """ Generates the ID and AC line for SP-EMBL """
    id_str = "ID   {GENE:<24}{REVIEW:<18}{AA_COUNT} AA.\n".format(
        GENE=gene,
        REVIEW="Unreviewed;",
        AA_COUNT=sequence_len
    )
    acc_str = "AC   {};".format(accession)
    return id_str + acc_str


def _get_month(num) -> str:
    """ Get the 3 letter code of the month """
    return dict(
        [
            (1, "JAN"), (2, "FEB"), (3, "MAR"), (4, "APR"), (5, "MAY"), (6, "JUN"),
            (7, "JUL"), (8, "AUG"), (9, "SEP"), (10, "OCT"), (11, "NOV"), (12, "DEC")
        ]
    )[num]


def _create_feature_dict(feature_table_file) -> dict:
    """ Parses the FeatureTable-File and returns a workable dictionary """
    feature_dict = dict()
    with open(feature_table_file, "r") as feature_table:
        csv_in = csv.reader(feature_table, delimiter="\t")

        header = [x.lower() for x in next(csv_in)]
        accession_idx = header.index("accession")
        type_idx = header.index("type")
        type_specific_idx = header.index("type_specific")
        description_idx = header.index("description")
        identifier = 2
        for line in csv_in:
            if line[accession_idx] not in feature_dict:
                feature_dict[line[accession_idx]] = dict()

            if line[type_idx] not in feature_dict[line[accession_idx]]:
                feature_dict[line[accession_idx]][line[type_idx]] = []

            # Insert feature entry
            feature_dict[line[accession_idx]][line[type_idx]].append(
                (line[type_specific_idx].split(","), line[description_idx], str(identifier))
            )
            identifier += 1

    return feature_dict


def _validate_position(position: str, feature_type: str, accession: str) -> bool:
    """ Check if position is either X or X..Y """
    x_valid = False
    y_valid = False
    if position:
        if ".." in position:
            x, y = position.split("..")
            # Check Y if available
            if y == "?":
                y_valid = True
            else:
                try:
                    int(y)
                    y_valid = True
                except ValueError:
                    pass
        else:
            y_valid = True
            x = position
        # Check X
        if x == "?":
            x_valid = True
        else:
            try:
                int(x)
                x_valid = True
            except ValueError:
                pass
    else:
        print(f"WARNING: Position invalid for {feature_type} in {accession} (position: '{position}').")
        return False

    if not x_valid or not y_valid:
        print(f"WARNING: Position invalid for {feature_type} in {accession} (position: '{position}').")
        return False

    return True


def _format_wrapped(ft_note_info: str) -> str:
    """
    Wraps the information provided in "/note=" to be maximally 80 characters wide.
    """
    first_line_prefix = 'FT                   /note="'
    continuation_prefix = 'FT                   '
    first_line_space = 80 - len(first_line_prefix)  # should be 51 chars
    continuation_space = 80 - len(continuation_prefix)  # should be 59 chars

    if len(ft_note_info) <= first_line_space - 1:
        # Fits and can be returned.
        return first_line_prefix + ft_note_info + "\""

    # ELSE: we wrap
    result_lines = []
    remaining_text = ft_note_info

    # Add first line
    result_lines.append(first_line_prefix + remaining_text[:first_line_space].rstrip())
    remaining_text = remaining_text[first_line_space:].lstrip()

    # Continue until we wrapped all the text in note
    while remaining_text:
        if len(remaining_text) <= continuation_space - 1:
            # Last line
            result_lines.append(continuation_prefix + remaining_text.rstrip() + "\"")
            break
        else:
            # Further lines
            part = remaining_text[:continuation_space]
            result_lines.append(continuation_prefix + part.rstrip())
            remaining_text = remaining_text[continuation_space:].lstrip()

    return '\n'.join(result_lines)


def _get_feature_tables_for_protein(feature_table, accession) -> str:
    """
    Generates the corresponding FT-Strings in SP-EMBL.

    Supported Features are:
    VARIANT, CONFLICT, MUTAGEN, (
        type_specific-Syntax: "original,replacement,position"
        or "Missing,position" for deletions
    ),
    SIGNAL, CHAIN, PROPEP, PEPTIDE (
        type_specific-Syntax: "position"
    ),
    and INIT_MET (
        type_specific-Syntax: "<None/Ignored>"
    ).

    The Position parameter needs to be formatted either as "X", or "X..Y".
    """

    if not feature_table:
        return ""

    if accession not in feature_table:
        return ""

    ft_str = ""
    for key in feature_table[accession].keys():
        if key == "VARIANT":
            for ft_var in feature_table[accession][key]:
                if len(ft_var[0]) == 3:  # CASE Replacement
                    if not _validate_position(ft_var[0][2], "VARIANT", accession):
                        continue
                    note = f"{ft_var[0][0]} -> {ft_var[0][1]} (in GEN_BY_PG; {ft_var[1]})"
                    ft_str += (
                        f'''\nFT   VARIANT         {ft_var[0][2]}\n''' +
                        f'''{_format_wrapped(note)}\n''' +
                        f'''FT                   /id="CUSTOM_{ft_var[2]}"'''
                    )
                elif len(ft_var[0]) == 2:  # CASE Deletion
                    if not _validate_position(ft_var[0][1], "VARIANT", accession):
                        continue
                    note = f"Missing (in GEN_BY_PG; {ft_var[1]})"
                    ft_str += (
                        f'''\nFT   VARIANT         {ft_var[0][1]}\n''' +
                        f'''{_format_wrapped(note)}\n''' +
                        f'''FT                   /id="CUSTOM_{ft_var[2]}"'''
                    )
        elif key == "MUTAGEN":
            for ft_var in feature_table[accession][key]:
                if len(ft_var[0]) == 3:  # CASE Replacement
                    if not _validate_position(ft_var[0][2], "MUTAGEN", accession):
                        continue
                    note = f"{ft_var[0][0]} -> {ft_var[0][1]}: in GEN_BY_PG; {ft_var[1]}"
                    ft_str += (
                        f'''\nFT   MUTAGEN         {ft_var[0][2]}\n''' +
                        f'''{_format_wrapped(note)}\n''' +
                        f'''FT                   /evidence="CUSTOM_{ft_var[2]}"'''
                    )
                elif len(ft_var[0]) == 2:  # CASE Deletion
                    if not _validate_position(ft_var[0][1], "MUTAGEN", accession):
                        continue
                    note = f"Missing: in GEN_BY_PG; {ft_var[1]}"
                    ft_str += (
                        f'''\nFT   MUTAGEN         {ft_var[0][1]}\n''' +
                        f'''{_format_wrapped(note)}\n''' +
                        f'''FT                   /evidence="CUSTOM_{ft_var[2]}"'''
                    )
        elif key == "CONFLICT":
            for ft_var in feature_table[accession][key]:
                if len(ft_var[0]) == 3:  # CASE Replacement
                    if not _validate_position(ft_var[0][2], "CONFLICT", accession):
                        continue
                    note = f"{ft_var[0][0]} -> {ft_var[0][1]} (in GEN_BY_PG; {ft_var[1]})"
                    ft_str += (
                        f'''\nFT   CONFLICT        {ft_var[0][2]}\n''' +
                        f'''{_format_wrapped(note)}\n''' +
                        f'''FT                   /evidence="CUSTOM_{ft_var[2]}"'''
                    )
                elif len(ft_var[0]) == 2:  # CASE Deletion
                    if not _validate_position(ft_var[0][1], "CONFLICT", accession):
                        continue
                    note = f"Missing (in GEN_BY_PG; {ft_var[1]})"
                    ft_str += (
                        f'''\nFT   CONFLICT        {ft_var[0][1]}\n''' +
                        f'''{_format_wrapped(note)}\n''' +
                        f'''FT                   /evidence="CUSTOM_{ft_var[2]}"'''
                    )
        elif key in ["CHAIN", "PROPEP", "PEPTIDE"]:
            for ft_cleaved in feature_table[accession][key]:
                position = ft_cleaved[0][0]  # Can only be X..Y
                if not _validate_position(position, key, accession):
                    continue
                ft_str += (
                    f'''\nFT   {key:<15} {position}\n''' +
                    f'''{_format_wrapped(ft_cleaved[1])}\n''' +
                    f'''FT                   /id="CUSTOM_{ft_cleaved[2]}"'''
                )
        elif key == "SIGNAL":
            for ft_cleaved in feature_table[accession][key]:
                position = ft_cleaved[0][0]  # Can only be X..Y
                if not _validate_position(position, "SIGNAL", accession):
                    continue
                ft_str += (
                    f'''\nFT   SIGNAL          {position}\n''' +
                    f'''{_format_wrapped(ft_cleaved[1])}\n''' +
                    f'''FT                   /evidence="CUSTOM_{ft_cleaved[2]}"'''
                )
        elif key == "INIT_MET":
            # Only process the first INIT_MET since it can only be applied once.
            if feature_table[accession][key]:
                ft_entry = feature_table[accession][key][0]  # Take only the first entry
                if len(feature_table[accession][key]) > 1:
                    print(
                        "WARNING: Multiple INIT_MET entries found for {accession}. "
                        "Only adding it once to the txt entry.".format(
                            accession=accession
                        )
                    )
                ft_str += (
                    '''\nFT   INIT_MET        1\n''' +
                    f'''{_format_wrapped(ft_entry[1])}\n''' +
                    f'''FT                   /evidence="CUSTOM_{ft_entry[2]}"'''
                )

    return ft_str


def generate_sp_embl_enty(sequence, accession, opt_feature) -> str:
    """ Generates a valid SP-EMBL using sequence, accession and optional features if provided. """

    return SWISS_EMBL_SKELETON.format(
        ID_AC=_get_id_ac_string(accession, accession, len(sequence)),
        DAY=date.today().day,
        MONTH=_get_month(date.today().month),
        YEAR=date.today().year,
        PROTEIN_DESC="Generated_by_ProtGraph",
        GENE=accession,
        ENSP=accession,
        FT=_get_feature_tables_for_protein(opt_feature, accession),
        SQ=_get_seq_header_string(len(sequence)),
        SEQ_BODY=_get_seq_string(sequence)
    )


def main():
    # Parse args
    args = parse_args()

    # Set in and output
    in_fasta = os.path.abspath(args.fasta_file[0])
    out_txt = os.path.abspath(args.output)
    feature_mapping = args.feature_tables
    if feature_mapping:
        feature_mapping = _create_feature_dict(os.path.abspath(feature_mapping))

    with open(in_fasta, "r") as in_file, open(out_txt, "w") as out_file:
        for sequence, pre, accession, description in tqdm.tqdm(
            get_next_fasta_entry(in_file), total=args.num_entries, unit="entries"
        ):
            out_file.write(generate_sp_embl_enty(sequence, accession, feature_mapping))
